{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-22T16:45:29.387682Z","iopub.execute_input":"2021-06-22T16:45:29.388100Z","iopub.status.idle":"2021-06-22T16:45:29.458649Z","shell.execute_reply.started":"2021-06-22T16:45:29.388007Z","shell.execute_reply":"2021-06-22T16:45:29.457627Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/data/Face_Test/Test/fear/168_m_f_f_b.jpg\n/kaggle/input/dataset/data/Face_Test/Test/fear/168_m_f_f_a.jpg\n/kaggle/input/dataset/data/Face_Test/Test/sadness/168_m_f_s_b.jpg\n/kaggle/input/dataset/data/Face_Test/Test/sadness/168_m_f_s_a.jpg\n/kaggle/input/dataset/data/Face_Test/Test/neutrality/168_m_f_n_a.jpg\n/kaggle/input/dataset/data/Face_Test/Test/neutrality/168_m_f_n_b.jpg\n/kaggle/input/dataset/data/Face_Test/Test/hapiness/168_m_f_h_b.jpg\n/kaggle/input/dataset/data/Face_Test/Test/hapiness/168_m_f_h_a.jpg\n/kaggle/input/dataset/data/Face_Test/Test/disgust/168_m_f_d_b.jpg\n/kaggle/input/dataset/data/Face_Test/Test/disgust/168_m_f_d_a.jpg\n/kaggle/input/dataset/data/Face_Test/Test/anger/168_m_f_a_a.jpg\n/kaggle/input/dataset/data/Face_Test/Test/anger/168_m_f_a_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/004_o_m_f_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/079_o_f_f_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/066_y_m_f_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/066_y_m_f_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/079_o_f_f_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/004_o_m_f_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/116_m_m_f_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/140_y_f_f_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/116_m_m_f_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/fear/140_y_f_f_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/116_m_m_s_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/079_o_f_s_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/004_o_m_s_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/066_y_m_s_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/066_y_m_s_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/004_o_m_s_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/140_y_f_s_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/140_y_f_s_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/116_m_m_s_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/sadness/079_o_f_s_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/066_y_m_n_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/079_o_f_n_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/079_o_f_n_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/116_m_m_n_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/004_o_m_n_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/004_o_m_n_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/116_m_m_n_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/140_y_f_n_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/140_y_f_n_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/neutrality/066_y_m_n_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/140_y_f_h_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/066_y_m_h_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/066_y_m_h_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/004_o_m_h_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/004_o_m_h_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/116_m_m_h_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/116_m_m_h_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/140_y_f_h_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/079_o_f_h_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/hapiness/079_o_f_h_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/079_o_f_d_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/004_o_m_d_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/116_m_m_d_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/140_y_f_d_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/066_y_m_d_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/079_o_f_d_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/066_y_m_d_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/004_o_m_d_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/140_y_f_d_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/disgust/116_m_m_d_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/004_o_m_a_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/079_o_f_a_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/140_y_f_a_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/066_y_m_a_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/066_y_m_a_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/079_o_f_a_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/116_m_m_a_b.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/004_o_m_a_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/116_m_m_a_a.jpg\n/kaggle/input/dataset/data/Face_Train/Train/anger/140_y_f_a_a.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport glob\nimport numpy\nimport cv2\nimport math\nimport matplotlib.pyplot as plt\nfrom skimage import io\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.transforms import Compose, ToTensor, Resize","metadata":{"execution":{"iopub.status.busy":"2021-06-22T16:45:53.860877Z","iopub.execute_input":"2021-06-22T16:45:53.861293Z","iopub.status.idle":"2021-06-22T16:45:56.884489Z","shell.execute_reply.started":"2021-06-22T16:45:53.861252Z","shell.execute_reply":"2021-06-22T16:45:56.883299Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#train and test data directory\ndata_dir = \"/kaggle/input/dataset/data/Face_Train/Train\"\ntest_data_dir = \"/kaggle/input/dataset/data/Face_Test/Test\"\n\n#load the train and test data\ndataset = ImageFolder(data_dir,transform = transforms.Compose([transforms.Resize((250,200)),transforms.ToTensor()]))\ntest_dataset = ImageFolder(test_data_dir,transforms.Compose([transforms.Resize((250,200)),transforms.ToTensor()]))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T16:45:57.861303Z","iopub.execute_input":"2021-06-22T16:45:57.861648Z","iopub.status.idle":"2021-06-22T16:45:57.879140Z","shell.execute_reply.started":"2021-06-22T16:45:57.861617Z","shell.execute_reply":"2021-06-22T16:45:57.878004Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(len(dataset))\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:03:46.333324Z","iopub.execute_input":"2021-06-22T03:03:46.334059Z","iopub.status.idle":"2021-06-22T03:03:46.34013Z","shell.execute_reply.started":"2021-06-22T03:03:46.334015Z","shell.execute_reply":"2021-06-22T03:03:46.339049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = dataset[0]\nprint(img.shape,label)\nprint(\"Clases del dataset : \\n\",dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:03:46.364021Z","iopub.execute_input":"2021-06-22T03:03:46.364446Z","iopub.status.idle":"2021-06-22T03:03:46.555441Z","shell.execute_reply.started":"2021-06-22T03:03:46.3644Z","shell.execute_reply":"2021-06-22T03:03:46.554202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_img(img,label):\n    print(f\"Label : {dataset.classes[label]}\")\n    plt.imshow(img.permute(1,2,0))\n\ndisplay_img(*dataset[1])","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:03:46.556756Z","iopub.execute_input":"2021-06-22T03:03:46.557199Z","iopub.status.idle":"2021-06-22T03:03:46.899481Z","shell.execute_reply.started":"2021-06-22T03:03:46.557157Z","shell.execute_reply":"2021-06-22T03:03:46.898399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\n#val_size = 4\n#train_size = len(dataset) - val_size \n#train_data,val_data = random_split(dataset,[train_size,val_size])\n#print(f\"Tamano del train : {len(train_data)}\")\n#print(f\"Tamano de la validacion : {len(val_data)}\")\n\ntrain_data=dataset\nval_data=test_dataset\n\ntrain_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 2, pin_memory = True)\nval_dl = DataLoader(val_data, batch_size*2, num_workers = 2, pin_memory = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:03:46.901623Z","iopub.execute_input":"2021-06-22T03:03:46.902052Z","iopub.status.idle":"2021-06-22T03:03:46.909783Z","shell.execute_reply.started":"2021-06-22T03:03:46.902008Z","shell.execute_reply":"2021-06-22T03:03:46.908505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(dl):\n    \"\"\"Plot images grid of single batch\"\"\"\n    for images, labels in dl:\n        fig,ax = plt.subplots(figsize = (16,12))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n        break\n        \nshow_batch(val_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:03:46.912022Z","iopub.execute_input":"2021-06-22T03:03:46.912499Z","iopub.status.idle":"2021-06-22T03:03:49.507136Z","shell.execute_reply.started":"2021-06-22T03:03:46.912453Z","shell.execute_reply":"2021-06-22T03:03:49.505996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(dl):\n    \"\"\"Plot images grid of single batch\"\"\"\n    for images, labels in dl:\n        fig,ax = plt.subplots(figsize = (16,12))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n        break\n        \nshow_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:03:49.508631Z","iopub.execute_input":"2021-06-22T03:03:49.508977Z","iopub.status.idle":"2021-06-22T03:04:02.22105Z","shell.execute_reply.started":"2021-06-22T03:03:49.508943Z","shell.execute_reply":"2021-06-22T03:04:02.219388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:04:02.223072Z","iopub.execute_input":"2021-06-22T03:04:02.223552Z","iopub.status.idle":"2021-06-22T03:04:02.233519Z","shell.execute_reply.started":"2021-06-22T03:04:02.223505Z","shell.execute_reply":"2021-06-22T03:04:02.232467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 6\n\nclass CNNAlex(CNN):\n    def __init__(self,num_classes=6):\n        super(CNNAlex, self).__init__()\n        self.network = nn.Sequential(\n            \n            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n            nn.ReLU(),\n            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n        \n            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            \n            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            \n            nn.Flatten(),\n            nn.Linear(82944,1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512,6)\n            \n        )\n        \n    def forward(self, xb):\n        return self.network(xb)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:04:02.234811Z","iopub.execute_input":"2021-06-22T03:04:02.235151Z","iopub.status.idle":"2021-06-22T03:04:02.254883Z","shell.execute_reply.started":"2021-06-22T03:04:02.235115Z","shell.execute_reply":"2021-06-22T03:04:02.253647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNIn(CNN):\n    def __init__(self,num_clases=6):\n        super(CNNIn,self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=2)\n        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n        self.relu3 = nn.ReLU()\n        self.conv4 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3, stride=1, padding=1)\n        self.relu4 = nn.ReLU()\n        self.fc = nn.Linear(in_features=125 * 100 * 24, out_features=num_classes)\n\n    def forward(self, input):\n        output = self.conv1(input)\n        output = self.relu1(output)\n        output = self.conv2(output)\n        output = self.relu2(output)\n        output = self.pool(output)\n        output = self.conv3(output)\n        output = self.relu3(output)\n        output = self.conv4(output)\n        output = self.relu4(output)\n        output = output.view(-1, 125 * 100 * 24)\n        output = self.fc(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:04:02.25841Z","iopub.execute_input":"2021-06-22T03:04:02.258921Z","iopub.status.idle":"2021-06-22T03:04:02.275621Z","shell.execute_reply.started":"2021-06-22T03:04:02.258869Z","shell.execute_reply":"2021-06-22T03:04:02.274323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\ndef testeo(model):\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in val_dl:\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (preds == labels).sum().item()\n        print(correct)\n        print(total)\n        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n\n@torch.no_grad()        \n\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n  \ndef fit(epochs, model, train_loader, val_loader, optimizer):\n    \n    history = []\n    for epoch in range(epochs):\n        \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:04:02.277871Z","iopub.execute_input":"2021-06-22T03:04:02.278345Z","iopub.status.idle":"2021-06-22T03:04:02.296999Z","shell.execute_reply.started":"2021-06-22T03:04:02.278297Z","shell.execute_reply":"2021-06-22T03:04:02.294697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50\nlearning_rate = 0.001\nmodel = CNNIn(6)\nopt_func = torch.optim.Adam(model.parameters(), lr = learning_rate)\n\nhistory = fit(num_epochs, model, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:15:23.52494Z","iopub.execute_input":"2021-06-22T04:15:23.525441Z","iopub.status.idle":"2021-06-22T04:29:54.679471Z","shell.execute_reply.started":"2021-06-22T04:15:23.525402Z","shell.execute_reply":"2021-06-22T04:29:54.67809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testeo(model)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:34:33.26664Z","iopub.execute_input":"2021-06-22T04:34:33.267064Z","iopub.status.idle":"2021-06-22T04:34:35.948467Z","shell.execute_reply.started":"2021-06-22T04:34:33.267029Z","shell.execute_reply":"2021-06-22T04:34:35.947343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grap(history):\n    #accuracies = [x['val_acc'] for x in history]\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    #plt.plot(accuracies, '-x')\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Entrenamiento','Validacion'])\n    plt.title('Grafico');\n\nplot_grap(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:34:39.520458Z","iopub.execute_input":"2021-06-22T04:34:39.520858Z","iopub.status.idle":"2021-06-22T04:34:39.684022Z","shell.execute_reply.started":"2021-06-22T04:34:39.520817Z","shell.execute_reply":"2021-06-22T04:34:39.6827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grap(history):\n    accuracies = [x['val_acc'] for x in history]\n    #train_losses = [x.get('train_loss') for x in history]\n    #val_acc = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    #plt.plot(train_losses, '-bx')\n    #plt.plot(val_acc, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('acc')\n    plt.legend(['Acurracy'])\n    plt.title('Grafico de accuracy');\n\nplot_grap(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:34:56.667072Z","iopub.execute_input":"2021-06-22T04:34:56.667494Z","iopub.status.idle":"2021-06-22T04:34:56.820899Z","shell.execute_reply.started":"2021-06-22T04:34:56.66746Z","shell.execute_reply":"2021-06-22T04:34:56.819649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef get_all_preds(model, loader):\n    all_preds = torch.tensor([])\n    for batch in loader:\n        images, labels = batch\n\n        preds = model(images)\n        all_preds = torch.cat(\n            (all_preds, preds)\n            ,dim=0\n        )\n    return all_preds\n\nget_all_preds(model,val_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:45:40.980611Z","iopub.execute_input":"2021-06-22T04:45:40.981098Z","iopub.status.idle":"2021-06-22T04:45:43.753246Z","shell.execute_reply.started":"2021-06-22T04:45:40.981042Z","shell.execute_reply":"2021-06-22T04:45:43.752052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    #prediction_loader = torch.utils.data.DataLoader(train_dl, batch_size=10000)\n    train_preds = get_all_preds(model, val_dl)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:48:36.145401Z","iopub.execute_input":"2021-06-22T04:48:36.145924Z","iopub.status.idle":"2021-06-22T04:48:38.86774Z","shell.execute_reply.started":"2021-06-22T04:48:36.145878Z","shell.execute_reply":"2021-06-22T04:48:38.866623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_preds.shape)\n#print(test_dataset.targets)\n#a=test_dataset.targets.unsqueeze(0)\n#print(a)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:10:15.412767Z","iopub.execute_input":"2021-06-22T05:10:15.41316Z","iopub.status.idle":"2021-06-22T05:10:15.419183Z","shell.execute_reply.started":"2021-06-22T05:10:15.413118Z","shell.execute_reply":"2021-06-22T05:10:15.417321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_num_correct(preds, labels):\n    labels=torch.from_numpy(np.array(labels))\n    return preds.argmax(dim=1).eq(labels).sum().item()\n\npreds_correct = get_num_correct(train_preds, test_dataset.targets)\nprint('total correct:', preds_correct)\nprint('accuracy:', preds_correct / len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:09:10.013635Z","iopub.execute_input":"2021-06-22T05:09:10.014002Z","iopub.status.idle":"2021-06-22T05:09:10.02481Z","shell.execute_reply.started":"2021-06-22T05:09:10.013972Z","shell.execute_reply":"2021-06-22T05:09:10.02315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=torch.from_numpy(np.array(test_dataset.targets))\nstacked = torch.stack((temp,train_preds.argmax(dim=1)),dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:13:06.655404Z","iopub.execute_input":"2021-06-22T05:13:06.655775Z","iopub.status.idle":"2021-06-22T05:13:06.661128Z","shell.execute_reply.started":"2021-06-22T05:13:06.655743Z","shell.execute_reply":"2021-06-22T05:13:06.660099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked[0].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:14:12.759834Z","iopub.execute_input":"2021-06-22T05:14:12.760523Z","iopub.status.idle":"2021-06-22T05:14:12.76693Z","shell.execute_reply.started":"2021-06-22T05:14:12.760472Z","shell.execute_reply":"2021-06-22T05:14:12.766216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmt = torch.zeros(10,10, dtype=torch.int64)\ncmt","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:18:27.502182Z","iopub.execute_input":"2021-06-22T05:18:27.502593Z","iopub.status.idle":"2021-06-22T05:18:27.510354Z","shell.execute_reply.started":"2021-06-22T05:18:27.502561Z","shell.execute_reply":"2021-06-22T05:18:27.509392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for p in stacked:\n    tl, pl = p.tolist()\n    print(tl,pl)\n    cmt[tl, pl] = cmt[tl, pl] + 1\n\ncmt","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:18:29.649035Z","iopub.execute_input":"2021-06-22T05:18:29.649468Z","iopub.status.idle":"2021-06-22T05:18:29.666957Z","shell.execute_reply.started":"2021-06-22T05:18:29.649429Z","shell.execute_reply":"2021-06-22T05:18:29.666251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(test_dataset.targets, train_preds.argmax(dim=1))\nprint(type(cm))\ncm","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:22:12.303106Z","iopub.execute_input":"2021-06-22T05:22:12.303467Z","iopub.status.idle":"2021-06-22T05:22:12.317026Z","shell.execute_reply.started":"2021-06-22T05:22:12.303437Z","shell.execute_reply":"2021-06-22T05:22:12.315991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:22:32.76063Z","iopub.execute_input":"2021-06-22T05:22:32.761446Z","iopub.status.idle":"2021-06-22T05:22:32.77215Z","shell.execute_reply.started":"2021-06-22T05:22:32.761385Z","shell.execute_reply":"2021-06-22T05:22:32.770702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, test_dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:23:15.060889Z","iopub.execute_input":"2021-06-22T05:23:15.061421Z","iopub.status.idle":"2021-06-22T05:23:15.612565Z","shell.execute_reply.started":"2021-06-22T05:23:15.061372Z","shell.execute_reply":"2021-06-22T05:23:15.611447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\nlearning_rate = 1.0\nmodel = CNNIn(6)\nopt_func = torch.optim.Adadelta(model.parameters(), lr = learning_rate,rho=0.9,eps=1e-06,weight_decay=0)\n\nhistory = fit(num_epochs, model, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:14:43.622871Z","iopub.execute_input":"2021-06-22T06:14:43.623349Z","iopub.status.idle":"2021-06-22T06:43:22.133127Z","shell.execute_reply.started":"2021-06-22T06:14:43.623312Z","shell.execute_reply":"2021-06-22T06:43:22.131976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grap(history):\n    #accuracies = [x['val_acc'] for x in history]\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    #plt.plot(accuracies, '-x')\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Entrenamiento','Validacion'])\n    plt.title('Grafico');\n\nplot_grap(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:44:33.852887Z","iopub.execute_input":"2021-06-22T06:44:33.853756Z","iopub.status.idle":"2021-06-22T06:44:34.092821Z","shell.execute_reply.started":"2021-06-22T06:44:33.853701Z","shell.execute_reply":"2021-06-22T06:44:34.091573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grap(history):\n    accuracies = [x['val_acc'] for x in history]\n    #train_losses = [x.get('train_loss') for x in history]\n    #val_acc = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    #plt.plot(train_losses, '-bx')\n    #plt.plot(val_acc, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('acc')\n    plt.legend(['Acurracy'])\n    plt.title('Grafico de accuracy');\n\nplot_grap(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:45:05.240612Z","iopub.execute_input":"2021-06-22T06:45:05.241027Z","iopub.status.idle":"2021-06-22T06:45:05.407691Z","shell.execute_reply.started":"2021-06-22T06:45:05.240995Z","shell.execute_reply":"2021-06-22T06:45:05.406372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50\nlearning_rate = 0.01\nmodel = CNNIn(6)\nopt_func = torch.optim.Adagrad(model.parameters(), lr = learning_rate,lr_decay=0,weight_decay=0,\n                               initial_accumulator_value=0,eps=1e-10)\n\nhistory = fit(num_epochs, model, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:49:54.755089Z","iopub.execute_input":"2021-06-22T06:49:54.75567Z","iopub.status.idle":"2021-06-22T07:04:20.659932Z","shell.execute_reply.started":"2021-06-22T06:49:54.755621Z","shell.execute_reply":"2021-06-22T07:04:20.658547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grap(history):\n    #accuracies = [x['val_acc'] for x in history]\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    #plt.plot(accuracies, '-x')\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Entrenamiento','Validacion'])\n    plt.title('Grafico');\n\nplot_grap(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:05:56.937498Z","iopub.execute_input":"2021-06-22T07:05:56.938135Z","iopub.status.idle":"2021-06-22T07:05:57.134472Z","shell.execute_reply.started":"2021-06-22T07:05:56.93806Z","shell.execute_reply":"2021-06-22T07:05:57.133446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grap(history):\n    accuracies = [x['val_acc'] for x in history]\n    #train_losses = [x.get('train_loss') for x in history]\n    #val_acc = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    #plt.plot(train_losses, '-bx')\n    #plt.plot(val_acc, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('acc')\n    plt.legend(['Acurracy'])\n    plt.title('Grafico de accuracy');\n\nplot_grap(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:06:01.722436Z","iopub.execute_input":"2021-06-22T07:06:01.723242Z","iopub.status.idle":"2021-06-22T07:06:01.883252Z","shell.execute_reply.started":"2021-06-22T07:06:01.723177Z","shell.execute_reply":"2021-06-22T07:06:01.881544Z"},"trusted":true},"execution_count":null,"outputs":[]}]}